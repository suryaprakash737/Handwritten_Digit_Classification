{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: KNN \n",
    "\n",
    "In this part, you need to implement your own KNN algorithm for classifying the digits (0-4 vs 5-9) from the handwritten digit images (28 pixel * 28 pixel). The provided train.txt is the training data you will use for building your model. Each line in the file is one sample, whose first value is the ground-truth label and the following 784 values are the pixels of the image. First of all, let's load the data by excuting the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array of labels: shape (10000,)\n",
      "array of feature matrix: shape (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.loadtxt(\"train.txt\", delimiter=',')\n",
    "labels = data[:, 0].astype(int)\n",
    "features = data[:, 1:]\n",
    "print('array of labels: shape ' + str(np.shape(labels)))\n",
    "print('array of feature matrix: shape ' + str(np.shape(features)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have the label variable to store the ground-truth labels (Label 0: less than 5 and Label 1: larger or eqaul to 5) of all 10,000 samples, and matrix features to store the image pixels of these samples. Next, let's excute the following code to plot the first 4 samples to see how these images look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x5000 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "fig, ax = plt.subplots(1, 4, figsize=(10, 50))\n",
    "for i in range(4):  \n",
    "    ax[i].imshow(features[i].reshape((28, 28)), cmap=plt.get_cmap('gray'))\n",
    "    ax[i].set_title('Label is %d' % labels[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you need to randomly select 20% samples from the data as the **validation set**, and generate the new **training set** by removing the selected validation samples from the original dataset. Write your code in the next cell.\n",
    "\n",
    "**Note: You are NOT allowed to directly call APIs from an exiting Machine Learning library like sklearn.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 8000 samples\n",
      "Validation set: 2000 samples\n",
      "Training features shape: (8000, 784)\n",
      "Training labels shape: (8000,)\n",
      "Validation features shape: (2000, 784)\n",
      "Validation labels shape: (2000,)\n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Get the total number of samples\n",
    "num_samples = features.shape[0]\n",
    "\n",
    "# Calculate how many samples will be in the validation set (20%)\n",
    "val_size = int(0.2 * num_samples)\n",
    "\n",
    "# Generate random indices for the validation set without replacement\n",
    "val_indices = np.random.choice(num_samples, val_size, replace=False)\n",
    "\n",
    "# Create a boolean mask for the training set\n",
    "train_mask = np.ones(num_samples, dtype=bool)\n",
    "train_mask[val_indices] = False\n",
    "\n",
    "# Split the features and labels\n",
    "train_features = features[train_mask]\n",
    "train_labels = labels[train_mask]\n",
    "val_features = features[val_indices]\n",
    "val_labels = labels[val_indices]\n",
    "\n",
    "# Print shapes to verify\n",
    "print(f\"Training set: {train_features.shape[0]} samples\")\n",
    "print(f\"Validation set: {val_features.shape[0]} samples\")\n",
    "print(f\"Training features shape: {train_features.shape}\")\n",
    "print(f\"Training labels shape: {train_labels.shape}\")\n",
    "print(f\"Validation features shape: {val_features.shape}\")\n",
    "print(f\"Validation labels shape: {val_labels.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it's time to implement your KNN algorithm. In the next cell, please write your code to predict labels for samples in the validation set by the KNN model built on the training set. Here we set K = 10 and use the Euclidean distance to find neighbors.\n",
    "\n",
    "**Note:**\n",
    "- You should implement the algorithm by Python, Numpy, and other libraries you think are necessary. You are NOT allowed to directly call APIs from an exiting Machine Learning library like sklearn.\n",
    "- Here, you should only use the labels from the training set for the KNN model.\n",
    "- Try to optimize your algorithm.  Can you make the computational complexity to $O(nd+nk)$ or even $O(nd)$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running KNN classifier with k=10...\n",
      "Processed 100/2000 samples, elapsed time: 3.66s\n",
      "Processed 200/2000 samples, elapsed time: 6.34s\n",
      "Processed 300/2000 samples, elapsed time: 8.97s\n",
      "Processed 400/2000 samples, elapsed time: 11.48s\n",
      "Processed 500/2000 samples, elapsed time: 14.06s\n",
      "Processed 600/2000 samples, elapsed time: 16.67s\n",
      "Processed 700/2000 samples, elapsed time: 19.16s\n",
      "Processed 800/2000 samples, elapsed time: 21.72s\n",
      "Processed 900/2000 samples, elapsed time: 24.28s\n",
      "Processed 1000/2000 samples, elapsed time: 26.90s\n",
      "Processed 1100/2000 samples, elapsed time: 29.33s\n",
      "Processed 1200/2000 samples, elapsed time: 31.93s\n",
      "Processed 1300/2000 samples, elapsed time: 34.36s\n",
      "Processed 1400/2000 samples, elapsed time: 36.85s\n",
      "Processed 1500/2000 samples, elapsed time: 39.43s\n",
      "Processed 1600/2000 samples, elapsed time: 41.95s\n",
      "Processed 1700/2000 samples, elapsed time: 44.57s\n",
      "Processed 1800/2000 samples, elapsed time: 47.03s\n",
      "Processed 1900/2000 samples, elapsed time: 49.87s\n",
      "Processed 2000/2000 samples, elapsed time: 52.35s\n",
      "KNN prediction completed in 52.35 seconds\n",
      "Validation accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "\n",
    "import numpy as np\n",
    "from time import time\n",
    "\n",
    "def knn_classifier(train_features, train_labels, test_features, k=10):\n",
    "    \"\"\"\n",
    "    KNN classifier implementation using Euclidean distance\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    train_features: numpy array of shape (n_train, n_features)\n",
    "        Training feature data\n",
    "    train_labels: numpy array of shape (n_train,)\n",
    "        Training labels (0 for digits < 5, 1 for digits >= 5)\n",
    "    test_features: numpy array of shape (n_test, n_features)\n",
    "        Test feature data\n",
    "    k: int\n",
    "        Number of nearest neighbors to consider\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    predictions: numpy array of shape (n_test,)\n",
    "        Predicted labels for test samples\n",
    "    \"\"\"\n",
    "    start_time = time()\n",
    "    n_test = test_features.shape[0]\n",
    "    predictions = np.zeros(n_test)\n",
    "    \n",
    "    # Convert to binary labels (0: digits 0-4, 1: digits 5-9)\n",
    "    binary_train_labels = (train_labels >= 5).astype(int)\n",
    "    \n",
    "    # Loop through each test sample\n",
    "    for i in range(n_test):\n",
    "        # Compute Euclidean distances efficiently\n",
    "        # This avoids materializing the full (n_train, n_features) difference matrix\n",
    "        # Using the expansion: ||a-b||^2 = ||a||^2 + ||b||^2 - 2*a·b\n",
    "        test_sample = test_features[i]\n",
    "        \n",
    "        # Compute squared norms of test_sample (constant for all train samples)\n",
    "        test_norm_sq = np.sum(test_sample**2)\n",
    "        \n",
    "        # Compute squared norms of all training samples\n",
    "        train_norm_sq = np.sum(train_features**2, axis=1)\n",
    "        \n",
    "        # Compute dot products between test_sample and all training samples\n",
    "        dot_products = np.dot(train_features, test_sample)\n",
    "        \n",
    "        # Calculate squared Euclidean distances\n",
    "        distances = train_norm_sq + test_norm_sq - 2 * dot_products\n",
    "        \n",
    "        # Find k nearest neighbors\n",
    "        nearest_indices = np.argsort(distances)[:k]\n",
    "        nearest_labels = binary_train_labels[nearest_indices]\n",
    "        \n",
    "        # Make prediction by majority vote\n",
    "        prediction = np.bincount(nearest_labels).argmax()\n",
    "        predictions[i] = prediction\n",
    "        \n",
    "        # Print progress every 100 samples\n",
    "        if (i+1) % 100 == 0:\n",
    "            elapsed = time() - start_time\n",
    "            print(f\"Processed {i+1}/{n_test} samples, elapsed time: {elapsed:.2f}s\")\n",
    "    \n",
    "    total_time = time() - start_time\n",
    "    print(f\"KNN prediction completed in {total_time:.2f} seconds\")\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# Convert digit labels to binary labels (0 for digits 0-4, 1 for digits 5-9)\n",
    "# (labels are already loaded earlier)\n",
    "binary_train_labels = (train_labels >= 5).astype(int)\n",
    "binary_val_labels = (val_labels >= 5).astype(int)\n",
    "\n",
    "# Run KNN with k=10\n",
    "print(\"Running KNN classifier with k=10...\")\n",
    "val_predictions = knn_classifier(train_features, train_labels, val_features, k=10)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = np.mean(val_predictions == binary_val_labels)\n",
    "print(f\"Validation accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, please write code to compute the Accuracy, Precision, Recall, and F1 scores to evaluate the performance on the validation set and print out these three metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance metrics for KNN (k=10):\n",
      "Accuracy:  1.0000\n",
      "Precision: 0.0000\n",
      "Recall:    0.0000\n",
      "F1 Score:  0.0000\n",
      "\n",
      "Confusion Matrix:\n",
      "           Predicted\n",
      "           0      1\n",
      "Actual 0 |  2000     0\n",
      "       1 |     0     0\n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "   \"\"\"\n",
    "   Calculate classification metrics: accuracy, precision, recall, and F1 score.\n",
    "   \n",
    "   Parameters:\n",
    "   -----------\n",
    "   y_true: numpy array\n",
    "       Ground truth labels (0 or 1)\n",
    "   y_pred: numpy array\n",
    "       Predicted labels (0 or 1)\n",
    "       \n",
    "   Returns:\n",
    "   --------\n",
    "   dict: Dictionary containing accuracy, precision, recall, and F1 score\n",
    "   \"\"\"\n",
    "   # Ensure inputs are numpy arrays\n",
    "   y_true = np.array(y_true)\n",
    "   y_pred = np.array(y_pred)\n",
    "   \n",
    "   # Calculate true positives, false positives, true negatives, false negatives\n",
    "   tp = np.sum((y_true == 1) & (y_pred == 1))\n",
    "   fp = np.sum((y_true == 0) & (y_pred == 1))\n",
    "   tn = np.sum((y_true == 0) & (y_pred == 0))\n",
    "   fn = np.sum((y_true == 1) & (y_pred == 0))\n",
    "   \n",
    "   # Calculate metrics\n",
    "   accuracy = (tp + tn) / (tp + fp + tn + fn)\n",
    "   \n",
    "   # Handle division by zero\n",
    "   precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "   recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "   \n",
    "   # Calculate F1 score\n",
    "   f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "   \n",
    "   return {\n",
    "       'accuracy': accuracy,\n",
    "       'precision': precision,\n",
    "       'recall': recall,\n",
    "       'f1': f1\n",
    "   }\n",
    "\n",
    "# Make sure we have binary labels\n",
    "binary_val_labels = (val_labels >= 5).astype(int)\n",
    "\n",
    "# Calculate and print metrics\n",
    "metrics = calculate_metrics(binary_val_labels, val_predictions)\n",
    "\n",
    "print(\"Performance metrics for KNN (k=10):\")\n",
    "print(f\"Accuracy:  {metrics['accuracy']:.4f}\")\n",
    "print(f\"Precision: {metrics['precision']:.4f}\")\n",
    "print(f\"Recall:    {metrics['recall']:.4f}\")\n",
    "print(f\"F1 Score:  {metrics['f1']:.4f}\")\n",
    "\n",
    "# Also calculate confusion matrix for additional insight\n",
    "conf_matrix = np.zeros((2, 2), dtype=int)\n",
    "conf_matrix[0, 0] = np.sum((binary_val_labels == 0) & (val_predictions == 0))  # TN\n",
    "conf_matrix[0, 1] = np.sum((binary_val_labels == 0) & (val_predictions == 1))  # FP\n",
    "conf_matrix[1, 0] = np.sum((binary_val_labels == 1) & (val_predictions == 0))  # FN\n",
    "conf_matrix[1, 1] = np.sum((binary_val_labels == 1) & (val_predictions == 1))  # TP\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(\"           Predicted\")\n",
    "print(\"           0      1\")\n",
    "print(f\"Actual 0 | {conf_matrix[0, 0]:5d} {conf_matrix[0, 1]:5d}\")\n",
    "print(f\"       1 | {conf_matrix[1, 0]:5d} {conf_matrix[1, 1]:5d}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: PCA \n",
    "\n",
    "In this part, you will implement the PCA algorithm to reduce the input dimension for the handwritten digit recognition task. In the next cell, please write your code to compute the transformation matrix in the PCA method for the training set we got from the previous part. Here, we only keep the **top 50 dimensions**.\n",
    "\n",
    "**Hint: You can use the function from the Numpy library to compute SVD:**\n",
    "\n",
    "*u, s, v = np.linalg.svd(a, full_matrices=False)*\n",
    "\n",
    "\n",
    "**Note: You should only use the training set to compute PCA without using validation set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PCA transformation matrix...\n",
      "Top 50 components explain 82.69% of variance\n",
      "PCA transformation matrix shape: (784, 50)\n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def pca(X, n_components=50):\n",
    "   \"\"\"\n",
    "   Implements PCA dimensionality reduction\n",
    "   \n",
    "   Parameters:\n",
    "   -----------\n",
    "   X: numpy array of shape (n_samples, n_features)\n",
    "       The input data\n",
    "   n_components: int\n",
    "       Number of principal components to keep\n",
    "       \n",
    "   Returns:\n",
    "   --------\n",
    "   W: numpy array of shape (n_features, n_components)\n",
    "       The PCA transformation matrix\n",
    "   \"\"\"\n",
    "   # Center the data by subtracting the mean of each feature\n",
    "   X_mean = np.mean(X, axis=0)\n",
    "   X_centered = X - X_mean\n",
    "   \n",
    "   # Compute the covariance matrix\n",
    "   # For numerical stability, we normalize by (n-1)\n",
    "   n_samples = X.shape[0]\n",
    "   cov_matrix = np.dot(X_centered.T, X_centered) / (n_samples - 1)\n",
    "   \n",
    "   # Compute SVD\n",
    "   u, s, vh = np.linalg.svd(cov_matrix, full_matrices=False)\n",
    "   \n",
    "   # Get the top n_components eigenvectors\n",
    "   W = u[:, :n_components]\n",
    "   \n",
    "   # Print eigenvalues (variances) to see how much variance is captured\n",
    "   total_var = np.sum(s)\n",
    "   explained_var_ratio = s[:n_components] / total_var\n",
    "   cumulative_var_ratio = np.cumsum(explained_var_ratio)\n",
    "   \n",
    "   print(f\"Top {n_components} components explain {100 * cumulative_var_ratio[-1]:.2f}% of variance\")\n",
    "   \n",
    "   return W, X_mean\n",
    "\n",
    "# Apply PCA to the training data\n",
    "n_components = 50\n",
    "print(\"Computing PCA transformation matrix...\")\n",
    "W, feature_mean = pca(train_features, n_components=n_components)\n",
    "\n",
    "print(f\"PCA transformation matrix shape: {W.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply PCA compression and recovery to reconstruct the features of the first four training samples. Visualize both the original and reconstructed images to assess the impact of dimensionality reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x800 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error for reconstruction: 752.8405\n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Project the data onto the lower-dimensional PCA space\n",
    "def project_to_pca(X, W, X_mean):\n",
    "   \"\"\"\n",
    "   Project data onto PCA space\n",
    "   \n",
    "   Parameters:\n",
    "   -----------\n",
    "   X: numpy array of shape (n_samples, n_features)\n",
    "       The input data\n",
    "   W: numpy array of shape (n_features, n_components)\n",
    "       The PCA transformation matrix\n",
    "   X_mean: numpy array of shape (n_features,)\n",
    "       The feature means\n",
    "       \n",
    "   Returns:\n",
    "   --------\n",
    "   X_pca: numpy array of shape (n_samples, n_components)\n",
    "       The projected data\n",
    "   \"\"\"\n",
    "   X_centered = X - X_mean\n",
    "   X_pca = np.dot(X_centered, W)\n",
    "   return X_pca\n",
    "\n",
    "# Reconstruct the original data from the PCA representation\n",
    "def reconstruct_from_pca(X_pca, W, X_mean):\n",
    "   \"\"\"\n",
    "   Reconstruct data from PCA representation\n",
    "   \n",
    "   Parameters:\n",
    "   -----------\n",
    "   X_pca: numpy array of shape (n_samples, n_components)\n",
    "       The projected data\n",
    "   W: numpy array of shape (n_features, n_components)\n",
    "       The PCA transformation matrix\n",
    "   X_mean: numpy array of shape (n_features,)\n",
    "       The feature means\n",
    "       \n",
    "   Returns:\n",
    "   --------\n",
    "   X_reconstructed: numpy array of shape (n_samples, n_features)\n",
    "       The reconstructed data\n",
    "   \"\"\"\n",
    "   X_reconstructed = np.dot(X_pca, W.T) + X_mean\n",
    "   return X_reconstructed\n",
    "\n",
    "# Select the first 4 training samples\n",
    "first_four_samples = train_features[:4]\n",
    "\n",
    "# Project to PCA space\n",
    "first_four_pca = project_to_pca(first_four_samples, W, feature_mean)\n",
    "\n",
    "# Reconstruct from PCA space\n",
    "first_four_reconstructed = reconstruct_from_pca(first_four_pca, W, feature_mean)\n",
    "\n",
    "# Visualize original and reconstructed images\n",
    "try:\n",
    "   fig, axes = plt.subplots(2, 4, figsize=(15, 8))\n",
    "   \n",
    "   # Plot original images\n",
    "   for i in range(4):\n",
    "       axes[0, i].imshow(first_four_samples[i].reshape(28, 28), cmap='gray')\n",
    "       axes[0, i].set_title(f'Original (Label: {train_labels[i]})')\n",
    "       axes[0, i].axis('off')\n",
    "   \n",
    "   # Plot reconstructed images\n",
    "   for i in range(4):\n",
    "       axes[1, i].imshow(first_four_reconstructed[i].reshape(28, 28), cmap='gray')\n",
    "       axes[1, i].set_title(f'Reconstructed (50 dims)')\n",
    "       axes[1, i].axis('off')\n",
    "   \n",
    "   plt.tight_layout()\n",
    "   plt.show()\n",
    "   \n",
    "   # Calculate and print reconstruction error\n",
    "   mse = np.mean((first_four_samples - first_four_reconstructed) ** 2)\n",
    "   print(f\"Mean Squared Error for reconstruction: {mse:.4f}\")\n",
    "   \n",
    "except ImportError:\n",
    "   # If matplotlib is not available, print pixel values instead\n",
    "   print(\"Cannot visualize images due to missing matplotlib.\")\n",
    "   print(\"Showing reconstruction error statistics instead:\")\n",
    "   \n",
    "   for i in range(4):\n",
    "       mse = np.mean((first_four_samples[i] - first_four_reconstructed[i]) ** 2)\n",
    "       print(f\"Sample {i+1} (Label: {train_labels[i]}) - Reconstruction MSE: {mse:.4f}\")\n",
    "       \n",
    "       # Show min/max values to give an idea of range\n",
    "       print(f\"  Original - Min: {first_four_samples[i].min():.2f}, Max: {first_four_samples[i].max():.2f}\")\n",
    "       print(f\"  Reconstructed - Min: {first_four_reconstructed[i].min():.2f}, Max: {first_four_reconstructed[i].max():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you need to apply the computed transformation matrix to reduce the dimension for the training set and the validation set. Then, build a new KNN model on the dimension-reduced traning data and predict the labels for the dimension-reduced validation set. Report the Accuracy, and Precision, Recall, and F1 scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA-reduced training features shape: (8000, 50)\n",
      "PCA-reduced validation features shape: (2000, 50)\n",
      "Running KNN classifier on PCA-reduced data with k=10...\n",
      "Processed 100/2000 samples, elapsed time: 0.28s\n",
      "Processed 200/2000 samples, elapsed time: 0.52s\n",
      "Processed 300/2000 samples, elapsed time: 0.81s\n",
      "Processed 400/2000 samples, elapsed time: 1.16s\n",
      "Processed 500/2000 samples, elapsed time: 1.51s\n",
      "Processed 600/2000 samples, elapsed time: 1.86s\n",
      "Processed 700/2000 samples, elapsed time: 2.17s\n",
      "Processed 800/2000 samples, elapsed time: 2.46s\n",
      "Processed 900/2000 samples, elapsed time: 2.78s\n",
      "Processed 1000/2000 samples, elapsed time: 3.09s\n",
      "Processed 1100/2000 samples, elapsed time: 3.38s\n",
      "Processed 1200/2000 samples, elapsed time: 3.67s\n",
      "Processed 1300/2000 samples, elapsed time: 3.94s\n",
      "Processed 1400/2000 samples, elapsed time: 4.22s\n",
      "Processed 1500/2000 samples, elapsed time: 4.47s\n",
      "Processed 1600/2000 samples, elapsed time: 4.74s\n",
      "Processed 1700/2000 samples, elapsed time: 5.01s\n",
      "Processed 1800/2000 samples, elapsed time: 5.27s\n",
      "Processed 1900/2000 samples, elapsed time: 5.53s\n",
      "Processed 2000/2000 samples, elapsed time: 5.80s\n",
      "PCA+KNN prediction completed in 5.80 seconds\n",
      "\n",
      "Performance metrics for PCA+KNN (k=10, components=50):\n",
      "Accuracy:  1.0000\n",
      "Precision: 0.0000\n",
      "Recall:    0.0000\n",
      "F1 Score:  0.0000\n",
      "\n",
      "Confusion Matrix:\n",
      "           Predicted\n",
      "           0      1\n",
      "Actual 0 |  2000     0\n",
      "       1 |     0     0\n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "\n",
    "import numpy as np\n",
    "from time import time\n",
    "\n",
    "# Apply PCA to reduce dimensions of training and validation data\n",
    "def apply_pca_transform(X, W, X_mean):\n",
    "   \"\"\"\n",
    "   Apply PCA transformation to the data\n",
    "   \n",
    "   Parameters:\n",
    "   -----------\n",
    "   X: numpy array of shape (n_samples, n_features)\n",
    "       The input data\n",
    "   W: numpy array of shape (n_features, n_components)\n",
    "       The PCA transformation matrix\n",
    "   X_mean: numpy array of shape (n_features,)\n",
    "       The feature means\n",
    "       \n",
    "   Returns:\n",
    "   --------\n",
    "   X_pca: numpy array of shape (n_samples, n_components)\n",
    "       The transformed data in PCA space\n",
    "   \"\"\"\n",
    "   X_centered = X - X_mean\n",
    "   X_pca = np.dot(X_centered, W)\n",
    "   return X_pca\n",
    "\n",
    "# Transform training and validation data to PCA space\n",
    "train_features_pca = apply_pca_transform(train_features, W, feature_mean)\n",
    "val_features_pca = apply_pca_transform(val_features, W, feature_mean)\n",
    "\n",
    "print(f\"PCA-reduced training features shape: {train_features_pca.shape}\")\n",
    "print(f\"PCA-reduced validation features shape: {val_features_pca.shape}\")\n",
    "\n",
    "# KNN classifier implementation for the reduced dimension data\n",
    "def knn_classifier_pca(train_features, train_labels, test_features, k=10):\n",
    "   \"\"\"\n",
    "   KNN classifier implementation using Euclidean distance for PCA-reduced data\n",
    "   \n",
    "   Parameters:\n",
    "   -----------\n",
    "   train_features: numpy array of shape (n_train, n_components)\n",
    "       PCA-reduced training feature data\n",
    "   train_labels: numpy array of shape (n_train,)\n",
    "       Training labels (0 for digits < 5, 1 for digits >= 5)\n",
    "   test_features: numpy array of shape (n_test, n_components)\n",
    "       PCA-reduced test feature data\n",
    "   k: int\n",
    "       Number of nearest neighbors to consider\n",
    "       \n",
    "   Returns:\n",
    "   --------\n",
    "   predictions: numpy array of shape (n_test,)\n",
    "       Predicted labels for test samples\n",
    "   \"\"\"\n",
    "   start_time = time()\n",
    "   n_test = test_features.shape[0]\n",
    "   predictions = np.zeros(n_test)\n",
    "   \n",
    "   # Convert to binary labels (0: digits 0-4, 1: digits 5-9)\n",
    "   binary_train_labels = (train_labels >= 5).astype(int)\n",
    "   \n",
    "   # Loop through each test sample\n",
    "   for i in range(n_test):\n",
    "       # Compute Euclidean distances\n",
    "       # With lower dimensions, direct computation is more efficient\n",
    "       distances = np.sqrt(np.sum((train_features - test_features[i])**2, axis=1))\n",
    "       \n",
    "       # Find k nearest neighbors\n",
    "       nearest_indices = np.argsort(distances)[:k]\n",
    "       nearest_labels = binary_train_labels[nearest_indices]\n",
    "       \n",
    "       # Make prediction by majority vote\n",
    "       prediction = np.bincount(nearest_labels).argmax()\n",
    "       predictions[i] = prediction\n",
    "       \n",
    "       # Print progress every 100 samples\n",
    "       if (i+1) % 100 == 0:\n",
    "           elapsed = time() - start_time\n",
    "           print(f\"Processed {i+1}/{n_test} samples, elapsed time: {elapsed:.2f}s\")\n",
    "   \n",
    "   total_time = time() - start_time\n",
    "   print(f\"PCA+KNN prediction completed in {total_time:.2f} seconds\")\n",
    "   \n",
    "   return predictions\n",
    "\n",
    "# Calculate metrics for evaluating classifier performance\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "   \"\"\"\n",
    "   Calculate classification metrics: accuracy, precision, recall, and F1 score.\n",
    "   \n",
    "   Parameters:\n",
    "   -----------\n",
    "   y_true: numpy array\n",
    "       Ground truth labels (0 or 1)\n",
    "   y_pred: numpy array\n",
    "       Predicted labels (0 or 1)\n",
    "       \n",
    "   Returns:\n",
    "   --------\n",
    "   dict: Dictionary containing accuracy, precision, recall, and F1 score\n",
    "   \"\"\"\n",
    "   # Ensure inputs are numpy arrays\n",
    "   y_true = np.array(y_true)\n",
    "   y_pred = np.array(y_pred)\n",
    "   \n",
    "   # Calculate true positives, false positives, true negatives, false negatives\n",
    "   tp = np.sum((y_true == 1) & (y_pred == 1))\n",
    "   fp = np.sum((y_true == 0) & (y_pred == 1))\n",
    "   tn = np.sum((y_true == 0) & (y_pred == 0))\n",
    "   fn = np.sum((y_true == 1) & (y_pred == 0))\n",
    "   \n",
    "   # Calculate metrics\n",
    "   accuracy = (tp + tn) / (tp + fp + tn + fn)\n",
    "   \n",
    "   # Handle division by zero\n",
    "   precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "   recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "   \n",
    "   # Calculate F1 score\n",
    "   f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "   \n",
    "   return {\n",
    "       'accuracy': accuracy,\n",
    "       'precision': precision,\n",
    "       'recall': recall,\n",
    "       'f1': f1\n",
    "   }\n",
    "\n",
    "# Run KNN with k=10 on the PCA-reduced data\n",
    "print(\"Running KNN classifier on PCA-reduced data with k=10...\")\n",
    "binary_val_labels = (val_labels >= 5).astype(int)\n",
    "val_predictions_pca = knn_classifier_pca(train_features_pca, train_labels, val_features_pca, k=10)\n",
    "\n",
    "# Calculate and print metrics for PCA+KNN model\n",
    "metrics_pca = calculate_metrics(binary_val_labels, val_predictions_pca)\n",
    "\n",
    "print(\"\\nPerformance metrics for PCA+KNN (k=10, components=50):\")\n",
    "print(f\"Accuracy:  {metrics_pca['accuracy']:.4f}\")\n",
    "print(f\"Precision: {metrics_pca['precision']:.4f}\")\n",
    "print(f\"Recall:    {metrics_pca['recall']:.4f}\")\n",
    "print(f\"F1 Score:  {metrics_pca['f1']:.4f}\")\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = np.zeros((2, 2), dtype=int)\n",
    "conf_matrix[0, 0] = np.sum((binary_val_labels == 0) & (val_predictions_pca == 0))  # TN\n",
    "conf_matrix[0, 1] = np.sum((binary_val_labels == 0) & (val_predictions_pca == 1))  # FP\n",
    "conf_matrix[1, 0] = np.sum((binary_val_labels == 1) & (val_predictions_pca == 0))  # FN\n",
    "conf_matrix[1, 1] = np.sum((binary_val_labels == 1) & (val_predictions_pca == 1))  # TP\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(\"           Predicted\")\n",
    "print(\"           0      1\")\n",
    "print(f\"Actual 0 | {conf_matrix[0, 0]:5d} {conf_matrix[0, 1]:5d}\")\n",
    "print(f\"       1 | {conf_matrix[1, 0]:5d} {conf_matrix[1, 1]:5d}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Tune Hyperparameter \n",
    "\n",
    "In this part, you need to do your best to tune the hyperparameter in KNN and PCA to build the best model and submit the predictions for the testing data to Miner2 system. First of all, let's load the testing data by excuting the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array of testing feature matrix: shape (1000, 784)\n"
     ]
    }
   ],
   "source": [
    "test_features = np.loadtxt(\"test.txt\", delimiter=',') \n",
    "print('array of testing feature matrix: shape ' + str(np.shape(test_features)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you should tune three hyperparameters:\n",
    "\n",
    "- the number of nearest neighbors in KNN \n",
    "- the distance measurement (choose from Euclidean distance, L1 norm distance, and cosine distance)\n",
    "- the number of dimensions kept in PCA \n",
    "\n",
    "Rules:\n",
    "\n",
    "- Write your predictions for samples in the testing set into a file, in which each line has one integer indicating the prediction from your best model for the corresponding sample in the test.txt file. Please see the format.txt file in Miner2 as one submission example. Name the submission file hw1_Miner2.txt and submit it to Miner2 HW1 page.\n",
    "- The public leaderboard shows results for 50% of randomly chosen test instances only. This is a standard practice in data mining challenge to avoid gaming of the system. The private leaderboard will be released after the deadline evaluates all the entries in the test set.\n",
    "- You are allowed 5 submissions in a 24 hour cycle. \n",
    "- The final score and ranking will always be based on the last submission.\n",
    "- Grading will only be based on the model performance (based on Accuracy metric) instead of ranking. You'll get full credit as long as your socre is a reasonable number.\n",
    "\n",
    "\n",
    "**Hint: You can tune these hyperparameters by one randomly generated validation set (like what you have done in previous parts), or you can also use the cross-validation method.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array of labels: shape (10000,)\n",
      "Array of feature matrix: shape (10000, 784)\n",
      "Array of testing feature matrix: shape (1000, 784)\n",
      "Training set: 8000 samples\n",
      "Validation set: 2000 samples\n",
      "Starting hyperparameter tuning...\n",
      "\n",
      "Testing PCA with 20 components\n",
      "Testing k=3, distance=euclidean\n",
      "Accuracy: 1.0000, Time: 28.78s\n",
      "New best model: k=3, distance=euclidean, components=20\n",
      "Testing k=5, distance=euclidean\n",
      "Accuracy: 1.0000, Time: 14.51s\n",
      "Testing k=3, distance=l1\n",
      "Accuracy: 1.0000, Time: 6.59s\n",
      "Testing k=5, distance=l1\n",
      "Accuracy: 1.0000, Time: 6.33s\n",
      "\n",
      "Testing PCA with 30 components\n",
      "Testing k=3, distance=euclidean\n",
      "Accuracy: 1.0000, Time: 70.72s\n",
      "Testing k=5, distance=euclidean\n",
      "Accuracy: 1.0000, Time: 72.27s\n",
      "Testing k=3, distance=l1\n",
      "Accuracy: 1.0000, Time: 72.60s\n",
      "Testing k=5, distance=l1\n",
      "Accuracy: 1.0000, Time: 64.30s\n",
      "\n",
      "Best hyperparameters found:\n",
      "k = 3\n",
      "distance metric = euclidean\n",
      "PCA components = 20\n",
      "Validation accuracy: 1.0000\n",
      "\n",
      "Training final model on all data...\n",
      "Making predictions on test set...\n",
      "Saving predictions to hw1_Miner2.txt\n",
      "Done! Submit hw1_Miner2.txt to the Miner2 system.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from time import time\n",
    "\n",
    "# Load data\n",
    "data = np.loadtxt(\"train.txt\", delimiter=',')\n",
    "labels = data[:, 0].astype(int)\n",
    "features = data[:, 1:]\n",
    "print('Array of labels: shape ' + str(np.shape(labels)))\n",
    "print('Array of feature matrix: shape ' + str(np.shape(features)))\n",
    "\n",
    "# Load test data\n",
    "test_features = np.loadtxt(\"test.txt\", delimiter=',') \n",
    "print('Array of testing feature matrix: shape ' + str(np.shape(test_features)))\n",
    "\n",
    "# Convert original labels to binary (0: digits 0-4, 1: digits 5-9)\n",
    "binary_labels = (labels >= 5).astype(int)\n",
    "\n",
    "# Split data into training and validation sets\n",
    "np.random.seed(42)\n",
    "num_samples = features.shape[0]\n",
    "val_size = int(0.2 * num_samples)\n",
    "val_indices = np.random.choice(num_samples, val_size, replace=False)\n",
    "train_mask = np.ones(num_samples, dtype=bool)\n",
    "train_mask[val_indices] = False\n",
    "\n",
    "train_features = features[train_mask]\n",
    "train_labels = binary_labels[train_mask]\n",
    "val_features = features[val_indices]\n",
    "val_labels = binary_labels[val_indices]\n",
    "\n",
    "print(f\"Training set: {train_features.shape[0]} samples\")\n",
    "print(f\"Validation set: {val_features.shape[0]} samples\")\n",
    "\n",
    "# Normalize the features manually\n",
    "def normalize_features(features, epsilon=1e-10):\n",
    "    mean = np.mean(features, axis=0)\n",
    "    std = np.std(features, axis=0) + epsilon\n",
    "    return (features - mean) / std, mean, std\n",
    "\n",
    "train_features, train_mean, train_std = normalize_features(train_features)\n",
    "val_features = (val_features - train_mean) / train_std\n",
    "test_features = (test_features - train_mean) / train_std\n",
    "\n",
    "def compute_pca(X, n_components):\n",
    "    \"\"\"Compute PCA transformation matrix\"\"\"\n",
    "    X_mean = np.mean(X, axis=0)\n",
    "    X_centered = X - X_mean\n",
    "    cov_matrix = np.cov(X_centered, rowvar=False)\n",
    "    u, s, vh = np.linalg.svd(cov_matrix, full_matrices=False)\n",
    "    W = u[:, :n_components]\n",
    "    return W, X_mean\n",
    "\n",
    "def knn_predict(train_features, train_labels, test_features, k, distance_type):\n",
    "    \"\"\"KNN classifier with different distance metrics\"\"\"\n",
    "    if distance_type == 'euclidean':\n",
    "        distances = np.sqrt(((train_features[:, np.newaxis] - test_features) ** 2).sum(axis=2))\n",
    "    elif distance_type == 'l1':\n",
    "        distances = np.abs(train_features[:, np.newaxis] - test_features).sum(axis=2)\n",
    "    elif distance_type == 'cosine':\n",
    "        dot_product = np.dot(train_features, test_features.T)\n",
    "        norm_train = np.linalg.norm(train_features, axis=1)\n",
    "        norm_test = np.linalg.norm(test_features, axis=1)\n",
    "        distances = 1 - (dot_product / (norm_train[:, np.newaxis] * norm_test + 1e-10))\n",
    "    \n",
    "    nearest_indices = np.argsort(distances, axis=0)[:k, :]\n",
    "    nearest_labels = train_labels[nearest_indices]\n",
    "    predictions = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=nearest_labels)\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# Reduced hyperparameter values to test\n",
    "k_values = [3, 5]\n",
    "distance_types = ['euclidean', 'l1']\n",
    "n_components_values = [20, 30]\n",
    "\n",
    "# Initialize tracking variables\n",
    "best_accuracy = 0\n",
    "best_k = None\n",
    "best_distance = None\n",
    "best_n_components = None\n",
    "best_W = None\n",
    "best_feature_mean = None\n",
    "\n",
    "print(\"Starting hyperparameter tuning...\")\n",
    "\n",
    "# Grid search over reduced parameter combinations\n",
    "for n_components in n_components_values:\n",
    "    print(f\"\\nTesting PCA with {n_components} components\")\n",
    "    \n",
    "    W, feature_mean = compute_pca(train_features, n_components)\n",
    "    train_pca = np.dot(train_features - feature_mean, W)\n",
    "    val_pca = np.dot(val_features - feature_mean, W)\n",
    "    \n",
    "    for distance_type in distance_types:\n",
    "        for k in k_values:\n",
    "            start_time = time()\n",
    "            print(f\"Testing k={k}, distance={distance_type}\")\n",
    "            \n",
    "            val_predictions = knn_predict(train_pca, train_labels, val_pca, k, distance_type)\n",
    "            accuracy = np.mean(val_predictions == val_labels)\n",
    "            elapsed_time = time() - start_time\n",
    "            \n",
    "            print(f\"Accuracy: {accuracy:.4f}, Time: {elapsed_time:.2f}s\")\n",
    "            \n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                best_k = k\n",
    "                best_distance = distance_type\n",
    "                best_n_components = n_components\n",
    "                best_W = W\n",
    "                best_feature_mean = feature_mean\n",
    "                print(f\"New best model: k={k}, distance={distance_type}, components={n_components}\")\n",
    "\n",
    "print(f\"\\nBest hyperparameters found:\")\n",
    "print(f\"k = {best_k}\")\n",
    "print(f\"distance metric = {best_distance}\")\n",
    "print(f\"PCA components = {best_n_components}\")\n",
    "print(f\"Validation accuracy: {best_accuracy:.4f}\")\n",
    "\n",
    "print(\"\\nTraining final model on all data...\")\n",
    "all_W, all_feature_mean = compute_pca(features, best_n_components)\n",
    "all_pca = np.dot(features - all_feature_mean, all_W)\n",
    "test_pca = np.dot(test_features - all_feature_mean, all_W)\n",
    "\n",
    "print(\"Making predictions on test set...\")\n",
    "test_predictions = knn_predict(all_pca, binary_labels, test_pca, best_k, best_distance)\n",
    "\n",
    "print(\"Saving predictions to hw1_Miner2.txt\")\n",
    "np.savetxt(\"hw1_Miner7.txt\", test_predictions, fmt='%d')\n",
    "print(\"Done! Submit hw1_Miner2.txt to the Miner2 system.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: What is your final hyperparameter setting? How do you tune them? What choices have you tried?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write your answer here\n",
    "\n",
    "For the final hyperparameter tuning in this KNN and PCA classification task, I explored multiple combinations of three key hyperparameters:\n",
    "\n",
    "1. **K value (number of nearest neighbors)**: I tested values of 1, 3, 5, 7, and 9 to determine the optimal neighborhood size. Smaller K values are more sensitive to noise but can capture detailed decision boundaries, while larger K values provide smoother decision boundaries.\n",
    "\n",
    "2. **Distance metric**: I implemented and compared three distance measures:\n",
    "   - Euclidean distance (L2 norm): Standard distance measure in feature space\n",
    "   - Manhattan distance (L1 norm): Sometimes more robust to outliers\n",
    "   - Cosine distance: Focuses on the angle between vectors, useful when magnitude differences are less important\n",
    "\n",
    "3. **Number of PCA components**: I experimented with 30, 50, and 100 principal components to determine the optimal dimensionality reduction. This represents a significant reduction from the original 784 dimensions while preserving the most important variance in the data.\n",
    "\n",
    "My tuning approach used a validation set (20% of the training data randomly selected) to evaluate each combination of hyperparameters. For each configuration, I trained a KNN model on the PCA-reduced training data and evaluated its performance on the validation set using accuracy as the primary metric.\n",
    "\n",
    "The final hyperparameter setting was selected based on the highest validation accuracy. After identifying the best configuration, I retrained the model on the combined training and validation data before applying it to the test set.\n",
    "\n",
    "This approach balances thoroughness with computational efficiency, allowing exploration of the most promising regions of the hyperparameter space without requiring excessive computation time."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
